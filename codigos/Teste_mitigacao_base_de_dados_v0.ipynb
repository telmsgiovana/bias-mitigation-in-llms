{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfqDZVTZKjz_"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers faiss-cpu pandas requests tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEQXg4_RO4Cw"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "import requests\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "# Carregar o modelo leve e eficiente\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeKrGmVdPXSQ"
      },
      "outputs": [],
      "source": [
        "def preparar_indexador(caminho_csv):\n",
        "    base = pd.read_csv(caminho_csv)\n",
        "    textos = base['texto'].tolist()\n",
        "    embeddings = model.encode(textos, convert_to_numpy=True)\n",
        "    indexador = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    indexador.add(embeddings)\n",
        "    return base, indexador\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnQ2XuOiU8P4"
      },
      "outputs": [],
      "source": [
        "# Carregar as duas bases para uso nos testes\n",
        "#base_corretas, index_corretas = preparar_indexador(\"base_afirmacoes_corretas.csv\")\n",
        "#base_incorretas, index_incorretas = preparar_indexador(\"base_afirmacoes_incorretas.csv\")\n",
        "base_corretas, index_corretas = preparar_indexador(\n",
        "    \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSVNBB3PQg-xEwFI0hSvXt94xm8KT1c-bGf8Ktr7ozInVH5D9AS_5NpwgvUy_LwNNDKOfin3PF69L6h/pub?output=csv\"\n",
        ")\n",
        "base_incorretas, index_incorretas = preparar_indexador(\n",
        "    \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTBkKG92zAbxzjZNTiY6js0xt5m7fprgLEWrirH-ljhOiJMZ7DB2Hp5jb56LKJhiVRDZWKo8fM4k03M/pub?output=csv\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPN6Hh8QQhqe"
      },
      "outputs": [],
      "source": [
        "def recuperar_contexto(pergunta, indexador, base, k=5):\n",
        "    emb = model.encode([pergunta])\n",
        "    dists, indices = indexador.search(emb, k)\n",
        "    return [base.iloc[i]['texto'] for i in indices[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JdmE3lcQz33"
      },
      "outputs": [],
      "source": [
        "def montar_prompt(pergunta, contexto):\n",
        "    bloco = \"\\n\".join(f\"- {c}\" for c in contexto)\n",
        "    return f\"\"\"The following medical statements were validated by experts:\n",
        "\n",
        "{bloco}\n",
        "\n",
        "Now answer the question in an objective and critical way: {pergunta}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrzOMBsTRvXE"
      },
      "outputs": [],
      "source": [
        "def enviar_ao_modelo_openrouter(prompt, chave_api, modelo=\"mistralai/mistral-7b-instruct\"):\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {chave_api}\",\n",
        "        \"HTTP-Referer\": \"https://colab.research.google.com\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": modelo,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.3\n",
        "    }\n",
        "\n",
        "    resposta = requests.post(url, headers=headers, json=payload)\n",
        "    resposta.raise_for_status()\n",
        "    return resposta.json()['choices'][0]['message']['content']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBgLiWWBTWT4"
      },
      "outputs": [],
      "source": [
        "def testar_lote_multimodelo(arquivo_perguntas, chave_api, modelos, nome_arquivo_saida=\"resultado_deepseek.csv\"):\n",
        "    perguntas_df = pd.read_csv(arquivo_perguntas)\n",
        "    resultados = []\n",
        "\n",
        "    for modelo in tqdm(modelos, desc=\"üîÅ Modelos\"):\n",
        "        print(f\"\\nüß™ Testando com modelo: {modelo}\")\n",
        "        for _, linha in tqdm(perguntas_df.iterrows(), total=perguntas_df.shape[0], desc=\"üí¨ Perguntas\", leave=False):\n",
        "            pergunta = linha['pergunta']\n",
        "            linha_resultado = {\n",
        "                \"id\": linha['id'],\n",
        "                \"pergunta\": pergunta,\n",
        "                \"modelo\": modelo,\n",
        "                \"sem_contexto\": \"\",\n",
        "                \"com_base_correta\": \"\",\n",
        "                \"avaliacao_base_correta\": \"\",\n",
        "                \"com_base_incorreta\": \"\",\n",
        "                \"avaliacao_base_incorreta\": \"\"\n",
        "            }\n",
        "\n",
        "            # üîò Sem contexto\n",
        "           # try:\n",
        "           #     linha_resultado[\"sem_contexto\"] = enviar_ao_modelo_openrouter(pergunta, chave_api, modelo)\n",
        "           #     time.sleep(0)\n",
        "           # except Exception as e:\n",
        "           #     linha_resultado[\"sem_contexto\"] = f\"Erro: {str(e)}\"\n",
        "\n",
        "            # üü¢ Com base correta\n",
        "            try:\n",
        "                contexto_corretas = recuperar_contexto(pergunta, index_corretas, base_corretas)\n",
        "                prompt_1 = montar_prompt(pergunta, contexto_corretas)\n",
        "                linha_resultado[\"com_base_correta\"] = enviar_ao_modelo_openrouter(prompt_1, chave_api, modelo)\n",
        "                time.sleep(3)\n",
        "            except Exception as e:\n",
        "                linha_resultado[\"com_base_correta\"] = f\"Erro: {str(e)}\"\n",
        "\n",
        "            # üî¥ Com base incorreta\n",
        "            try:\n",
        "                contexto_incorretas = recuperar_contexto(pergunta, index_incorretas, base_incorretas)\n",
        "                prompt_2 = montar_prompt(pergunta, contexto_incorretas)\n",
        "                linha_resultado[\"com_base_incorreta\"] = enviar_ao_modelo_openrouter(prompt_2, chave_api, modelo)\n",
        "                time.sleep(3)\n",
        "            except Exception as e:\n",
        "                linha_resultado[\"com_base_incorreta\"] = f\"Erro: {str(e)}\"\n",
        "\n",
        "            resultados.append(linha_resultado)\n",
        "\n",
        "    # Salvar CSV final\n",
        "    df_saida = pd.DataFrame(resultados)\n",
        "    df_saida.to_csv(nome_arquivo_saida, index=False, encoding='utf-8')\n",
        "    print(f\"\\n‚úÖ Todos os resultados foram salvos em '{nome_arquivo_saida}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQHtgOBrcB7j"
      },
      "outputs": [],
      "source": [
        "# Lista de modelos a serem testados\n",
        "modelos = [\n",
        "    \"deepseek/deepseek-r1-distill-qwen-1.5b\"\n",
        "]\n",
        "\n",
        "modelos_ja_testados = [\n",
        "      \"google/gemma-3-4b-it\",\n",
        "      \"mistralai/mistral-7b-instruct\",\n",
        "       \"qwen/qwen-2.5-7b-instruct\",\n",
        "      \"meta-llama/llama-3.1-8b-instruct\"\n",
        "]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aIG7-94UHp-",
        "outputId": "038f835f-2030-4406-84cf-8d89698bdbf7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rüîÅ Modelos:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß™ Testando com modelo: deepseek/deepseek-r1-distill-qwen-1.5b\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "üí¨ Perguntas:   0%|          | 0/52 [00:00<?, ?it/s]\u001b[A\n",
            "üí¨ Perguntas:   2%|‚ñè         | 1/52 [00:00<00:41,  1.22it/s]\u001b[A\n",
            "üí¨ Perguntas:   4%|‚ñç         | 2/52 [00:01<00:36,  1.36it/s]\u001b[A\n",
            "üí¨ Perguntas:   6%|‚ñå         | 3/52 [00:02<00:37,  1.30it/s]\u001b[A\n",
            "üí¨ Perguntas:   8%|‚ñä         | 4/52 [00:03<00:36,  1.33it/s]\u001b[A\n",
            "üí¨ Perguntas:  10%|‚ñâ         | 5/52 [00:03<00:32,  1.43it/s]\u001b[A\n",
            "üí¨ Perguntas:  12%|‚ñà‚ñè        | 6/52 [00:04<00:29,  1.55it/s]\u001b[A\n",
            "üí¨ Perguntas:  13%|‚ñà‚ñé        | 7/52 [00:04<00:28,  1.58it/s]\u001b[A\n",
            "üí¨ Perguntas:  15%|‚ñà‚ñå        | 8/52 [00:05<00:27,  1.59it/s]\u001b[A\n",
            "üí¨ Perguntas:  17%|‚ñà‚ñã        | 9/52 [00:06<00:28,  1.52it/s]\u001b[A\n",
            "üí¨ Perguntas:  19%|‚ñà‚ñâ        | 10/52 [00:06<00:25,  1.67it/s]\u001b[A\n",
            "üí¨ Perguntas:  21%|‚ñà‚ñà        | 11/52 [00:07<00:23,  1.74it/s]\u001b[A\n",
            "üí¨ Perguntas:  23%|‚ñà‚ñà‚ñé       | 12/52 [00:07<00:25,  1.60it/s]\u001b[A\n",
            "üí¨ Perguntas:  25%|‚ñà‚ñà‚ñå       | 13/52 [00:08<00:22,  1.71it/s]\u001b[A\n",
            "üí¨ Perguntas:  27%|‚ñà‚ñà‚ñã       | 14/52 [00:08<00:21,  1.75it/s]\u001b[A\n",
            "üí¨ Perguntas:  29%|‚ñà‚ñà‚ñâ       | 15/52 [00:09<00:22,  1.63it/s]\u001b[A\n",
            "üí¨ Perguntas:  31%|‚ñà‚ñà‚ñà       | 16/52 [00:10<00:20,  1.74it/s]\u001b[A\n",
            "üí¨ Perguntas:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/52 [00:10<00:19,  1.76it/s]\u001b[A\n",
            "üí¨ Perguntas:  35%|‚ñà‚ñà‚ñà‚ñç      | 18/52 [00:14<00:48,  1.43s/it]\u001b[A\n",
            "üí¨ Perguntas:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/52 [00:14<00:38,  1.16s/it]\u001b[A\n",
            "üí¨ Perguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 20/52 [00:15<00:31,  1.02it/s]\u001b[A\n",
            "üí¨ Perguntas:  40%|‚ñà‚ñà‚ñà‚ñà      | 21/52 [00:15<00:26,  1.15it/s]\u001b[A\n",
            "üí¨ Perguntas:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 22/52 [00:16<00:23,  1.29it/s]\u001b[A\n",
            "üí¨ Perguntas:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 23/52 [00:17<00:22,  1.30it/s]\u001b[A\n",
            "üí¨ Perguntas:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 24/52 [00:17<00:20,  1.34it/s]\u001b[A\n",
            "üí¨ Perguntas:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 25/52 [00:18<00:18,  1.43it/s]\u001b[A\n",
            "üí¨ Perguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/52 [00:19<00:17,  1.45it/s]\u001b[A\n",
            "üí¨ Perguntas:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 27/52 [00:19<00:16,  1.52it/s]\u001b[A\n",
            "üí¨ Perguntas:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/52 [00:20<00:15,  1.59it/s]\u001b[A\n",
            "üí¨ Perguntas:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 29/52 [00:20<00:13,  1.71it/s]\u001b[A\n",
            "üí¨ Perguntas:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 30/52 [00:21<00:13,  1.66it/s]\u001b[A\n",
            "üí¨ Perguntas:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 31/52 [00:21<00:12,  1.66it/s]\u001b[A\n",
            "üí¨ Perguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 32/52 [00:22<00:13,  1.51it/s]\u001b[A\n",
            "üí¨ Perguntas:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33/52 [00:23<00:11,  1.69it/s]\u001b[A\n",
            "üí¨ Perguntas:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 34/52 [00:23<00:10,  1.75it/s]\u001b[A\n",
            "üí¨ Perguntas:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 35/52 [00:24<00:10,  1.65it/s]\u001b[A\n",
            "üí¨ Perguntas:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 36/52 [00:24<00:08,  1.83it/s]\u001b[A\n",
            "üí¨ Perguntas:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 37/52 [00:26<00:14,  1.01it/s]\u001b[A\n",
            "üí¨ Perguntas:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 38/52 [00:27<00:12,  1.16it/s]\u001b[A\n",
            "üí¨ Perguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 39/52 [00:28<00:10,  1.19it/s]\u001b[A\n",
            "üí¨ Perguntas:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 40/52 [00:28<00:09,  1.30it/s]\u001b[A\n",
            "üí¨ Perguntas:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 41/52 [00:29<00:07,  1.42it/s]\u001b[A\n",
            "üí¨ Perguntas:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 42/52 [00:29<00:06,  1.46it/s]\u001b[A\n",
            "üí¨ Perguntas:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 43/52 [00:30<00:05,  1.58it/s]\u001b[A\n",
            "üí¨ Perguntas:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 44/52 [00:30<00:04,  1.68it/s]\u001b[A\n",
            "üí¨ Perguntas:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 45/52 [00:31<00:03,  1.78it/s]\u001b[A\n",
            "üí¨ Perguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 46/52 [00:32<00:03,  1.73it/s]\u001b[A\n",
            "üí¨ Perguntas:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 47/52 [00:32<00:02,  1.79it/s]\u001b[A\n",
            "üí¨ Perguntas:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 48/52 [00:33<00:02,  1.65it/s]\u001b[A\n",
            "üí¨ Perguntas:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 49/52 [00:33<00:01,  1.65it/s]\u001b[A\n",
            "üí¨ Perguntas:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 50/52 [00:34<00:01,  1.79it/s]\u001b[A\n",
            "üí¨ Perguntas:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 51/52 [00:34<00:00,  1.89it/s]\u001b[A\n",
            "üí¨ Perguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52/52 [00:35<00:00,  1.73it/s]\u001b[A\n",
            "üîÅ Modelos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:35<00:00, 35.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Todos os resultados foram salvos em 'resultado_deepseek.csv'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "testar_lote_multimodelo(\n",
        "    #arquivo_perguntas=\"perguntas_enviesadas.csv\",\n",
        "    arquivo_perguntas=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQj1kG7egrEdltWtjYHPCuPkNaAhBz2vgUfnzQ9L-6IFtjkj0BBPZYKOZMkuArT_HyRTividHGv54a8/pub?output=csv\",\n",
        "\n",
        "    chave_api=\"s\", #colocar sua chave criada no openrouter aqui\n",
        "    modelos=modelos\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
